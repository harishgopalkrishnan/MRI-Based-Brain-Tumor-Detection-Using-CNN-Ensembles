!pip install tensorflow==2.13.0 opencv-python-headless matplotlib scikit-learn --quiet

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
from glob import glob
import json
from pathlib import Path
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score

DATASET_ROOT = "/mnt/data/Brain_Tumor_Dataset"  # <-- change if different
TRAIN_DIR = os.path.join(DATASET_ROOT, "Training")
TEST_DIR = os.path.join(DATASET_ROOT, "Testing")

IMG_SIZE = (256, 256)
BATCH_SIZE = 32
NUM_CLASSES = 4
EPOCHS = 30
SEED = 42

def preprocess_and_save(src_root, dst_root, img_size=IMG_SIZE):
    os.makedirs(dst_root, exist_ok=True)
    for cls in os.listdir(src_root):
        cls_path = os.path.join(src_root, cls)
        if not os.path.isdir(cls_path):
            continue
        dst_cls = os.path.join(dst_root, cls)
        os.makedirs(dst_cls, exist_ok=True)
        for img_path in glob(os.path.join(cls_path, "*")):
            try:
                img = cv2.imread(img_path)
                if img is None:
                    continue
                blurred = cv2.GaussianBlur(img, (5,5), 0)
                gray = cv2.cvtColor(blurred, cv2.COLOR_BGR2GRAY)
                _, th = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
                kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3))
                eroded = cv2.erode(th, kernel, iterations=1)
                dilated = cv2.dilate(eroded, kernel, iterations=1)
                contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                if contours:
                    c = max(contours, key=cv2.contourArea)
                    x,y,w,h = cv2.boundingRect(c)
                    pad = int(0.05 * max(w,h))
                    x1 = max(0, x-pad); y1 = max(0, y-pad)
                    x2 = min(img.shape[1], x+w+pad); y2 = min(img.shape[0], y+h+pad)
                    roi = img[y1:y2, x1:x2]
                else:
                    roi = img
                final = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
                final = cv2.resize(final, img_size)
                out_path = os.path.join(dst_cls, Path(img_path).stem + ".png")
                cv2.imwrite(out_path, final)
            except Exception as e:
                print("Error:", e)
    print(f"Preprocessing complete for {src_root} -> {dst_root}")

PROCESSED_ROOT = "/mnt/data/Processed_Brain_Tumor"
TRAIN_PROCESSED = os.path.join(PROCESSED_ROOT, "train")
TEST_PROCESSED = os.path.join(PROCESSED_ROOT, "test")

if not os.path.exists(TRAIN_PROCESSED):
    preprocess_and_save(TRAIN_DIR, TRAIN_PROCESSED)
if not os.path.exists(TEST_PROCESSED):
    preprocess_and_save(TEST_DIR, TEST_PROCESSED)

train_gen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=15,
    width_shift_range=0.1,
    height_shift_range=0.1,
    zoom_range=0.1,
    horizontal_flip=True
)
test_gen = ImageDataGenerator(rescale=1./255)

train_data = train_gen.flow_from_directory(
    TRAIN_PROCESSED,
    target_size=IMG_SIZE,
    color_mode="grayscale",
    batch_size=BATCH_SIZE,
    class_mode="categorical",
    shuffle=True,
    seed=SEED
)
test_data = test_gen.flow_from_directory(
    TEST_PROCESSED,
    target_size=IMG_SIZE,
    color_mode="grayscale",
    batch_size=BATCH_SIZE,
    class_mode="categorical",
    shuffle=False
)
CLASS_INDICES = train_data.class_indices
print("Classes:", CLASS_INDICES)

def to_rgb(x):
    return np.repeat(x, 3, axis=-1)

def rgb_generator(gen):
    while True:
        x, y = next(gen)
        x_rgb = np.concatenate([x, x, x], axis=-1)
        yield x_rgb, y

train_rgb = rgb_generator(train_data)
test_rgb = rgb_generator(test_data)

train_steps = int(np.ceil(train_data.samples / BATCH_SIZE))
test_steps = int(np.ceil(test_data.samples / BATCH_SIZE))


def build_head(base_model):
    x = base_model.output
    x = layers.GlobalAveragePooling2D()(x)
    x = layers.Dense(512, activation='relu')(x)
    x = layers.Dropout(0.5)(x)
    outputs = layers.Dense(NUM_CLASSES, activation='softmax')(x)
    return keras.Model(inputs=base_model.input, outputs=outputs)

IMG_SHAPE = IMG_SIZE + (3,)

def get_vgg19(): 
    base = keras.applications.VGG19(weights='imagenet', include_top=False, input_shape=IMG_SHAPE)
    for layer in base.layers[:-4]: layer.trainable=False
    return build_head(base)

def get_resnet50v2():
    base = keras.applications.ResNet50V2(weights='imagenet', include_top=False, input_shape=IMG_SHAPE)
    for layer in base.layers[:-10]: layer.trainable=False
    return build_head(base)

def get_inceptionv3():
    base = keras.applications.InceptionV3(weights='imagenet', include_top=False, input_shape=IMG_SHAPE)
    for layer in base.layers[:-20]: layer.trainable=False
    return build_head(base)

def get_mobilenetv2():
    base = keras.applications.MobileNetV2(weights='imagenet', include_top=False, input_shape=IMG_SHAPE)
    for layer in base.layers[:-30]: layer.trainable=False
    return build_head(base)

def get_xception():
    base = keras.applications.Xception(weights='imagenet', include_top=False, input_shape=IMG_SHAPE)
    for layer in base.layers[:-30]: layer.trainable=False
    return build_head(base)


models = {
    "vgg19": get_vgg19,
    "resnet50v2": get_resnet50v2,
    "inceptionv3": get_inceptionv3,
    "mobilenetv2": get_mobilenetv2,
    "xception": get_xception
}

results = {}

for name, fn in models.items():
    print(f"\n=== Training {name} ===")
    model = fn()
    model.compile(optimizer=keras.optimizers.Adam(1e-4),
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])
    callbacks = [
        keras.callbacks.ModelCheckpoint(f"{name}.h5", save_best_only=True, monitor='val_accuracy'),
        keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)
    ]
    history = model.fit(
        train_rgb,
        steps_per_epoch=train_steps,
        validation_data=test_rgb,
        validation_steps=test_steps,
        epochs=EPOCHS,
        callbacks=callbacks
    )
    val_loss, val_acc = model.evaluate(test_rgb, steps=test_steps)
    print(f"{name} Accuracy: {val_acc:.4f}")
    results[name] = {"accuracy": val_acc, "loss": val_loss}

probs = None
for name in models.keys():
    model = keras.models.load_model(f"{name}.h5")
    preds = model.predict(test_rgb, steps=test_steps, verbose=0)
    probs = preds if probs is None else probs + preds
probs /= len(models)
y_true = test_data.classes
y_pred = np.argmax(probs, axis=1)
ensemble_acc = np.mean(y_pred == y_true)
print("Ensemble Accuracy:", ensemble_acc)
print(classification_report(y_true, y_pred, target_names=list(CLASS_INDICES.keys())))

with open("results_summary.json", "w") as f:
    json.dump(results, f, indent=2)
print("Saved results_summary.json")


print(\"Paper dataset layout detected. Ensemble training complete. You can inspect saved .h5 models and metrics above.\")


from sklearn.metrics import roc_curve, auc

def compute_metrics(y_true, y_pred, probs, class_names):
    cm = confusion_matrix(y_true, y_pred)
    report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)
    metrics_dict = {}

    # Compute specificity for each class
    spec = []
    for i in range(len(class_names)):
        tn = cm.sum() - (cm[i,:].sum() + cm[:,i].sum() - cm[i,i])
        fp = cm[:,i].sum() - cm[i,i]
        spec.append(tn / (tn + fp) if (tn + fp) != 0 else 0)

    for idx, label in enumerate(class_names):
        metrics_dict[label] = {
            "Precision": report[label]["precision"],
            "Recall": report[label]["recall"],
            "F1-score": report[label]["f1-score"],
            "Specificity": spec[idx]
        }
    # Macro-averaged AUC for multiclass One-vs-Rest
    y_true_bin = keras.utils.to_categorical(y_true, num_classes=len(class_names))
    aucs = []
    for i in range(len(class_names)):
        fpr, tpr, _ = roc_curve(y_true_bin[:,i], probs[:,i])
        aucs.append(auc(fpr, tpr))
    metrics_dict["AUC"] = np.mean(aucs)
    return cm, metrics_dict, aucs

def plot_confusion_matrix(cm, class_names, title="Confusion Matrix"):
    plt.figure(figsize=(6,6))
    plt.imshow(cm, interpolation="nearest", cmap=plt.cm.Blues)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(class_names))
    plt.xticks(tick_marks, class_names, rotation=45)
    plt.yticks(tick_marks, class_names)
    plt.ylabel("True label")
    plt.xlabel("Predicted label")
    thresh = cm.max() / 2.
    for i, j in np.ndindex(cm.shape):
        plt.text(j, i, format(cm[i, j], 'd'),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")
    plt.tight_layout()
    plt.show()

def plot_roc_auc(y_true, probs, class_names, title="ROC Curve"):
    plt.figure()
    y_true_bin = keras.utils.to_categorical(y_true, num_classes=len(class_names))
    for i in range(len(class_names)):
        fpr, tpr, _ = roc_curve(y_true_bin[:,i], probs[:,i])
        roc_auc = auc(fpr, tpr)
        plt.plot(fpr, tpr, label=f"{class_names[i]} (AUC = {roc_auc:.3f})")
    plt.plot([0,1], [0,1], "k--", alpha=0.7)
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.title(title)
    plt.legend(loc="lower right")
    plt.show()

# Store all model results in a structured dictionary
all_results = {}
for name in list(models.keys()) + ['ensemble']:
    if name == 'ensemble':
        probs_to_use = probs
        y_pred_to_use = y_pred
        label = 'Ensemble'
    else:
        model = keras.models.load_model(f"{name}.h5")
        probs_to_use = model.predict(test_rgb, steps=test_steps, verbose=0)
        y_pred_to_use = np.argmax(probs_to_use, axis=1)
        label = name.upper()
    cm, metrics, aucs = compute_metrics(y_true, y_pred_to_use, probs_to_use, list(CLASS_INDICES.keys()))
    all_results[label] = {"confusion_matrix": cm, "metrics": metrics}
    # Plot Confusion Matrix and ROC Curve for each model
    plot_confusion_matrix(cm, list(CLASS_INDICES.keys()), title=f"{label} Confusion Matrix")
    plot_roc_auc(y_true, probs_to_use, list(CLASS_INDICES.keys()), title=f"{label} ROC Curve")
    print(f"\n{label} Metrics:")
    for class_label, vals in metrics.items():
        if class_label == "AUC":
            print(f"  Macro-Averaged AUC: {vals:.4f}")
        else:
            print(f"  {class_label}: Precision={vals['Precision']:.4f}, Recall={vals['Recall']:.4f}, F1={vals['F1-score']:.4f}, Specificity={vals['Specificity']:.4f}")

# Summary table:
import pandas as pd
summary = pd.DataFrame()
for model_name, data in all_results.items():
    metrics = data['metrics']
    row = { f"{model_name}_{k}_{met}":v
          for k, results in metrics.items() if k != "AUC"
          for met,v in results.items()}
    row[f"{model_name}_Macro_AUC"] = metrics['AUC']
    summary = pd.concat([summary, pd.DataFrame([row])], ignore_index=True)
summary.T  # transpose for compact view
